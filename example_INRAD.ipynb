{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koussayinsat12/INRAD/blob/master/example_INRAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KyeongJoong/INRAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KriWivdxv8Ot",
        "outputId": "0905b4e0-c007-43c6-b2e1-44517955407f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'INRAD'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 59 (delta 11), reused 28 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), 8.83 MiB | 6.24 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./INRAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieSRTPDswJbo",
        "outputId": "8d8e5903-00ac-406e-dcae-6e794586497a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/INRAD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import data_loader\n",
        "import modules\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch._C import device\n",
        "import utils\n",
        "import eval_methods\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "IcHJEWlKdSZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customized Dataset Setting"
      ],
      "metadata": {
        "id": "ISV9VBqmdSZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# customized dataset structure\n",
        "'''\n",
        "You need to define x_train, x_test, y_test variable as followed with ndarray format.\n",
        "x_train: train data (usually without any label)\n",
        "x_test: test data\n",
        "y_test: label for test data. (1: anomaly, 0: normal)\n",
        "'''\n",
        "\n",
        "# We use one of the entity in SMD dataset for customized setting example.\n",
        "PATH = \"/content/INRAD/data/\"\n",
        "dataset = data_loader.dataset_choice(\"SMD\", path = PATH)\n",
        "data = next(iter(dataset))\n",
        "\n",
        "x_train = data.x_train\n",
        "x_test = data.x_test\n",
        "y_test = data.y_test\n",
        "\n",
        "x_dim = x_train.shape[1] # dimension of given time-series data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is multi-entity dataset.\n"
          ]
        }
      ],
      "metadata": {
        "id": "cGIANRHxdSaB",
        "outputId": "6b268ef1-04b6-4937-e787-cfe09d62334b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# data shape\n",
        "print(\"train data shape: \", x_train.shape)\n",
        "print(\"test data shape: \", x_test.shape)\n",
        "print(\"label data shape: \", y_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape:  (28479, 38)\n",
            "test data shape:  (28479, 38)\n",
            "label data shape:  (28479,)\n"
          ]
        }
      ],
      "metadata": {
        "id": "RPEP_wK8dSaD",
        "outputId": "ba8d7357-b862-4402-acab-1148dd380213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proposed Model (INRAD)"
      ],
      "metadata": {
        "id": "AZg2ezPXdSaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## temporal encoding"
      ],
      "metadata": {
        "id": "PNMzdNG7dSaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# If acutal timestamps are not available, you can arbitrarily make timestamps as belowed.\n",
        "train_timestamp = None\n",
        "\n",
        "# For the detailed understanding, please refer to the attached technical appendix pdf file.\n",
        "\n",
        "# default start: 2021-01-01 00:00:00\n",
        "# default interval unit : 1 minute\n",
        "\n",
        "# making timestamps for train set\n",
        "if train_timestamp is None:\n",
        "    train_timestamps = modules.timestamp_maker(\n",
        "        len(x_train) + 1,\n",
        "    )\n",
        "# '+1' is needed for setting start timestamp for test set\n",
        "\n",
        "# making timestamps for test set\n",
        "test_timestamps = modules.timestamp_maker(\n",
        "                        len(x_test), start=train_timestamps[-1], unit=\"1 min\"\n",
        "                    )"
      ],
      "outputs": [],
      "metadata": {
        "id": "4bRtuZWsdSaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# train data timestamps\n",
        "print(train_timestamps[:-1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 00:01:00',\n",
            "               '2021-01-01 00:02:00', '2021-01-01 00:03:00',\n",
            "               '2021-01-01 00:04:00', '2021-01-01 00:05:00',\n",
            "               '2021-01-01 00:06:00', '2021-01-01 00:07:00',\n",
            "               '2021-01-01 00:08:00', '2021-01-01 00:09:00',\n",
            "               ...\n",
            "               '2021-01-20 18:29:00', '2021-01-20 18:30:00',\n",
            "               '2021-01-20 18:31:00', '2021-01-20 18:32:00',\n",
            "               '2021-01-20 18:33:00', '2021-01-20 18:34:00',\n",
            "               '2021-01-20 18:35:00', '2021-01-20 18:36:00',\n",
            "               '2021-01-20 18:37:00', '2021-01-20 18:38:00'],\n",
            "              dtype='datetime64[ns]', length=28479, freq='T')\n"
          ]
        }
      ],
      "metadata": {
        "id": "ZpOvvihGdSaI",
        "outputId": "10aa1ca1-14ec-43db-f40e-d374751e38d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "# test data timestamps\n",
        "print(test_timestamps)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2021-01-20 18:39:00', '2021-01-20 18:40:00',\n",
            "               '2021-01-20 18:41:00', '2021-01-20 18:42:00',\n",
            "               '2021-01-20 18:43:00', '2021-01-20 18:44:00',\n",
            "               '2021-01-20 18:45:00', '2021-01-20 18:46:00',\n",
            "               '2021-01-20 18:47:00', '2021-01-20 18:48:00',\n",
            "               ...\n",
            "               '2021-02-09 13:08:00', '2021-02-09 13:09:00',\n",
            "               '2021-02-09 13:10:00', '2021-02-09 13:11:00',\n",
            "               '2021-02-09 13:12:00', '2021-02-09 13:13:00',\n",
            "               '2021-02-09 13:14:00', '2021-02-09 13:15:00',\n",
            "               '2021-02-09 13:16:00', '2021-02-09 13:17:00'],\n",
            "              dtype='datetime64[ns]', length=28479, freq='T')\n"
          ]
        }
      ],
      "metadata": {
        "id": "u-NkvJ0GdSaI",
        "outputId": "6381ba13-1bc8-4a30-9740-ed77f401742b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# temporal encoding\n",
        "train_encoded_input = modules.temporal_encoding(train_timestamps[:-1])\n",
        "test_encoded_input = modules.temporal_encoding(test_timestamps)"
      ],
      "outputs": [],
      "metadata": {
        "id": "C0JM6xZAdSaJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# encoded time (input of our method) for train set\n",
        "print(train_encoded_input)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "        [-1.0000, -1.0000, -1.0000, -1.0000, -0.9661, -1.0000],\n",
            "        [-1.0000, -1.0000, -1.0000, -1.0000, -0.9322, -1.0000],\n",
            "        ...,\n",
            "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2203, -1.0000],\n",
            "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2542, -1.0000],\n",
            "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2881, -1.0000]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "OfmVM_AUdSaJ",
        "outputId": "7d6456c1-94e7-4172-a081-87638cf4731e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# encoded time (input of our method) for test set\n",
        "print(test_encoded_input)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0000, -1.0000,  0.2667,  0.5652,  0.3220, -1.0000],\n",
            "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.3559, -1.0000],\n",
            "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.3898, -1.0000],\n",
            "        ...,\n",
            "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4915, -1.0000],\n",
            "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4576, -1.0000],\n",
            "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4237, -1.0000]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "G8eNCOWDdSaL",
        "outputId": "1dd07121-a056-4dd0-f90d-7dc7b2c8f795",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implicit Neural Representation model"
      ],
      "metadata": {
        "id": "kmd9kqjtdSaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "# Hyperparameters\n",
        "# We fix these across all datasets\n",
        "hidden_dim=256\n",
        "batch_size=131072 # 2^17 (full batch as long as memory capacity allows)\n",
        "epochs=1 # For simplicity, we set it as 1, however originally we set it as 10000\n",
        "earlystopping_patience=30\n",
        "first_omega_0=3000\n",
        "\n",
        "# Model initialization\n",
        "\n",
        "model = modules.Siren(\n",
        "    in_features=train_encoded_input.shape[1],\n",
        "    out_features=x_dim,\n",
        "    hidden_features=hidden_dim,\n",
        "    hidden_layers=3,\n",
        "    first_omega_0=first_omega_0,\n",
        "    outermost_linear=True,\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())"
      ],
      "outputs": [],
      "metadata": {
        "id": "m8SOM8oOdSaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "# Implicit Nerual Representation Learning on train set.\n",
        "\n",
        "data_train = modules.Timedata(x_train, train_encoded_input)\n",
        "train_dataloader = DataLoader(\n",
        "    data_train,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "early_stopping = utils.EarlyStopping(\n",
        "    patience=earlystopping_patience, verbose=False\n",
        ")\n",
        "\n",
        "epoch_time = []\n",
        "for step in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "    model_loss = 0\n",
        "    for batch_model_input, batch_ground_truth in train_dataloader:\n",
        "        batch_model_input = batch_model_input.to(device)\n",
        "        batch_ground_truth = batch_ground_truth.to(device)\n",
        "\n",
        "        batch_model_output, _ = model(batch_model_input)\n",
        "        loss = F.mse_loss(batch_model_output, batch_ground_truth)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        model_loss += loss.item()\n",
        "        batch_model_input = batch_model_input.detach().cpu()\n",
        "        batch_ground_truth = batch_ground_truth.detach().cpu()\n",
        "    epoch_time.append(time.time() - epoch_start)\n",
        "    early_stopping(model_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        break\n",
        "\n",
        "print(\"average training time per epoch: \", np.mean(epoch_time))\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average training time per epoch:  2.1139070987701416\n"
          ]
        }
      ],
      "metadata": {
        "id": "ERlcDqLQdSaN",
        "outputId": "619e7581-ce05-4ddd-a580-810ea608a7b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# Implicit Nerual Representation Learning on test set (re_training). For adopting variants of our method, INRAD-c, you can directly start this phase without using train set.\n",
        "\n",
        "data_test = modules.Timedata(x_test, test_encoded_input)\n",
        "test_dataloader = DataLoader(\n",
        "    data_test,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "early_stopping = utils.EarlyStopping(\n",
        "    patience=earlystopping_patience, verbose=False\n",
        ")\n",
        "\n",
        "print(\"re-training start\")\n",
        "for step in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "    model_loss = 0\n",
        "    for batch_model_input, batch_ground_truth in train_dataloader:\n",
        "        batch_model_input = batch_model_input.to(device)\n",
        "        batch_ground_truth = batch_ground_truth.to(device)\n",
        "        batch_model_output, _ = model(batch_model_input)\n",
        "        loss = F.mse_loss(batch_model_output, batch_ground_truth)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        model_loss += loss.item()\n",
        "        batch_model_input = batch_model_input.detach().cpu()\n",
        "        batch_ground_truth = batch_ground_truth.detach().cpu()\n",
        "    early_stopping(model_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        break\n",
        "print(\"re-training end\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "re-training start\n",
            "re-training end\n"
          ]
        }
      ],
      "metadata": {
        "id": "MtSFGCq1dSaO",
        "outputId": "b3ed3a16-79d9-481c-c51b-95ea97bcb367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# anomaly score calculation\n",
        "total_input = data_test.timepoints\n",
        "model = model.cpu()\n",
        "total_ground_truth = data_test.data_ready\n",
        "total_model_output, _ = model(total_input)\n",
        "\n",
        "anomaly_score = np.mean(\n",
        "    np.abs(\n",
        "        np.squeeze(\n",
        "            total_ground_truth.numpy()\n",
        "            - total_model_output.detach().cpu().numpy()\n",
        "        )\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "# The larger the anomaly score is, the higher possiblity of abnormal status is."
      ],
      "outputs": [],
      "metadata": {
        "id": "QboUogRRdSaP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# Evaluation based on Best F1-score\n",
        "# Note that for simplicity, we set number of epoch as 1.\n",
        "\n",
        "accuracy, threshold = eval_methods.bf_search(anomaly_score, y_test, verbose = False)\n",
        "print(\"Precision: {}, Recall {}, F1-score: {}\".format(accuracy[1], accuracy[2], accuracy[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9224167493222906, Recall 0.9974016295567868, F1-score: 0.9584398053764527\n"
          ]
        }
      ],
      "metadata": {
        "id": "OA24sWXbdSaQ",
        "outputId": "bdab718f-74f1-40a2-bf45-d3dc03b74024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict=eval_methods.adjust_predicts(anomaly_score, y_test,threshold=threshold)"
      ],
      "metadata": {
        "id": "BESu4uzwyfHp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "print(threshold)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20719709\n"
          ]
        }
      ],
      "metadata": {
        "id": "TUXgkjI5dSaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "535d4d36-fce2-43d0-a563-5f02f3cfb6e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(anomaly_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUYu9qM1yH7E",
        "outputId": "07da99dd-781a-4305-f314-0624c9087286"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08282907 0.08987705 0.0882763  ... 0.08141977 0.07976653 0.06307383]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.where(y_test==1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syt9u4h3z9mG",
        "outputId": "2a725791-3f7d-4285-a03f-5d1645273d2f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([15849, 15850, 15851, ..., 26115, 27554, 27555]),)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit ('fsl': conda)"
    },
    "interpreter": {
      "hash": "ed0093afbaab5e3a38124b5a58fa107641efd0b5f7403fd83a5aac98f7695b22"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}